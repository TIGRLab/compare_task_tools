{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-618b5c292ed7>:12: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n",
      "  from nistats.design_matrix import make_first_level_design_matrix, make_second_level_design_matrix\n",
      "/mnt/tigrlab/projects/ttan/fMRI_tools/.fMRI_env/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bids import BIDSLayout\n",
    "import nibabel as nib\n",
    "from nistats.design_matrix import make_first_level_design_matrix, make_second_level_design_matrix\n",
    "from nistats.design_matrix import check_design_matrix\n",
    "from nistats.reporting import plot_design_matrix, plot_contrast_matrix\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.model import TContrastResults\n",
    "from nilearn import surface\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_epi, plot_img, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_events(event_file):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        event_file Full path to events.tsv file\n",
    "    \n",
    "    Output:\n",
    "        event_df Newly formatted events dataframe\n",
    "    \"\"\"\n",
    "    #Read in tsv file\n",
    "    event_df = pd.read_csv(event_file,delimiter='\\t')\n",
    "    \n",
    "    #Filter out the desired columns from event_df \n",
    "    event= event_df[['trial_type','onset','duration']]\n",
    " \n",
    "    #Define EA and Circle video trial types\n",
    "    EA_videos = event[event_df['trial_type'] == 'EA_block']\n",
    "    circle_videos = event[event_df['trial_type'] == 'circle_block']\n",
    "    \n",
    "    #Define button press event type from dataframe\n",
    "    button_press = event_df[['onset','event_type','stim_file','duration']]\n",
    "    button_press = button_press[button_press['event_type'] == 'button_press']\n",
    "\n",
    "    #Filter button press during circle stimulus\n",
    "    circle_button_press = button_press[button_press['stim_file'].str.match(\"circles\")]\n",
    "    EA_button_press = button_press[button_press['stim_file'].str.match(\"NW|AR|TA\")]\n",
    "    \n",
    "    #Rename the button_press during circle block to circle button press\n",
    "    circle_button_press=circle_button_press.reset_index(drop=True)\n",
    "    circle_button_press.loc[:,'event_type'] = 'circle_button_press'\n",
    "    EA_button_press=EA_button_press.reset_index(drop=True)\n",
    "    EA_button_press.loc[:,'event_type'] = 'EA_button_press'\n",
    "    EA_button_press[\"event_type\"].replace({\"button_press\": \"EA_button_press\"}, inplace=True)   \n",
    "\n",
    "    #Merge EA and circle button press together\n",
    "    df_button_press = pd.concat([EA_button_press,circle_button_press])\n",
    "\n",
    "    #Drop stim_file column in the button press dataframe\n",
    "    df_button_press.drop(['stim_file'], axis=1,inplace=True)\n",
    "    \n",
    "    #Rename event_type column to trial_type in button press df\n",
    "    df_button_press.rename(columns={\"event_type\": \"trial_type\"}, inplace=True)\n",
    "    \n",
    "    #Merge all the event types together\n",
    "    event_df = pd.concat([EA_videos,circle_videos,df_button_press])\n",
    "    event_df=event_df.reset_index(drop=True)\n",
    "    #final_df.to_csv('/projects/ttan/fMRI_tools/sub-CMH0012_EA_onsets_run-01_fixed.tsv', sep = '\\t')\n",
    "    \n",
    "    return event_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_confounds(confound_path,fixed_confound_path, confound_vars):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        confound_path    Full path to confounds.tsv\n",
    "        confound_vars    List of confound variables to extract\n",
    "        tr_drop\n",
    "        dt               Compute temporal derivatives [default = True]\n",
    "        sq               Compute quadratic terms [default = False]\n",
    "    \n",
    "    Outputs:\n",
    "        confound_df\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in data using pandas and extract the relevant columns\n",
    "    confound_df = pd.read_csv(confound_path, delimiter='\\t')\n",
    "    confound_df = confound_df[confound_vars]\n",
    "    \n",
    "    #Load in the fixed csf and white matter data\n",
    "    fixed_confound_df = pd.read_csv(fixed_confound_path, delimiter='\\t')\n",
    "    confound_df[['csf','white_matter']] = fixed_confound_df[['csf_fixed','white_matter_fixed']].values\n",
    "    \n",
    "    # During the initial stages of a functional scan there is a strong signal decay artifact\n",
    "    # The first few TRs are very high intensity signals that don't reflect the rest of the scan\n",
    "    # so they are dropped\n",
    "    confound_df = confound_df.loc[tr_drop:].reset_index(drop=True)\n",
    "    \n",
    "    # Return confound matrix\n",
    "    return confound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define all necessary inputs to create a design matrix\n",
    "cifti_img = os.path.join('/projects/ttan/fMRI_tools/data/preprocessed/sub-CMH0012/', next(f for f in files if f.endswith('run-1_desc-preproc_Atlas_s6.dtseries.nii')))\n",
    "nifti_img = os.path.join('/projects/ttan/fMRI_tools/data/preprocessed/sub-CMH0012/', next(f for f in files if f.endswith('run-1_desc-preproc_Atlas_s6.nii')))\n",
    "func_img = nib.load(nifti_img)\n",
    "func_data = func_img.get_data()\n",
    "n_scans = func_img.shape[-1]\n",
    "\n",
    "#Define the time repettion from bid json file \n",
    "import os\n",
    "data_dir='/archive/data/SPINS/data/bids'\n",
    "json_file = os.path.join(data_dir,'sub-CMH0012', 'ses-01/func',\n",
    "                         'sub-CMH0012_ses-01_task-emp_run-1_bold.json')\n",
    "import json\n",
    "with open(json_file, 'r') as f:\n",
    "    t_r = json.load(f)['RepetitionTime']\n",
    "    \n",
    "#t_r=2\n",
    "frame_times = np.arange(n_scans)*t_r\n",
    "\n",
    "\n",
    "# design matrix input\n",
    "drift_model = 'polynomial'\n",
    "drift_order = 5\n",
    "hrf_model = 'spm'\n",
    "\n",
    "# first level model input\n",
    "noise_model = 'ar1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parametric modulation for EA_video \n",
    "def get_dm_pmod(fmri_img,event_file,confound_df):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "        fmri_img        Full path to ciftify outputs\n",
    "        event_file      Full path to event tsv file\n",
    "        confound_df     output from extract_confounds\n",
    "    \n",
    "    Outputs:\n",
    "        dm_pm\n",
    "    \"\"\"\n",
    "    #Calculate frame times\n",
    "    func_img = nib.load(fmri_img)\n",
    "    n_scans = func_img.shape[-1]\n",
    "    frame_times = np.arange(n_scans)*t_r\n",
    "    \n",
    "    #Filter out EA_pmod from event file\n",
    "    #event_file = '/mnt/tigrlab/projects/ttan/fMRI_tools/data/preprocessed/sub-CMH0012/SPN01_CMH_0012_01_01_EMP_part1.tsv' \n",
    "    event = pd.read_csv(event_file,delimiter='\\t')\n",
    "    event= event[['trial_type','onset','duration','block_score']]\n",
    "    \n",
    "    EA_videos_pmod = event[event['trial_type']=='EA_block']\n",
    "    EA_videos_pmod=EA_videos_pmod.reset_index(drop=True)\n",
    "\n",
    "    # This approach allow separating the modulated regressor from the main effect regressor\n",
    "    EA_videos_pmod.rename(columns= {\"block_score\": \"modulation\"}, inplace=True)\n",
    "    #mean-cneter modulation to orthogonalize w.r.t main effect of condition\n",
    "    EA_videos_pmod['modulation']= EA_videos_pmod['modulation'] - EA_videos_pmod['modulation'].mean()\n",
    "\n",
    "    EA_videos_pmod[\"trial_type\"].replace({\"EA_block\": \"EA_pmod\"}, inplace=True)\n",
    "    # create design matrix with modulation\n",
    "    dm_pm = make_first_level_design_matrix(frame_times,EA_videos_pmod,\n",
    "                                           drift_model=drift_model,\n",
    "                                           drift_order=drift_order,\n",
    "                                           add_regs=confound_df,\n",
    "                                           add_reg_names=list(confound_df.columns),\n",
    "                                           hrf_model=hrf_model\n",
    "                                          )\n",
    "    \n",
    "    return dm_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove modulation column from event_df\n",
    "#Create a design matrix with pmod as the reressor\n",
    "def get_design_matrix(fmri_img,event_file,dm_pm):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    fmri_img        full path to functional data\n",
    "    event_file      full path to event type tsv file\n",
    "    dm_pm           design matrix for parametric modulation\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    dm              a full design matrix\n",
    "    \"\"\"\n",
    "    event=format_events(event_file)\n",
    "    func_img = nib.load(fmri_img)\n",
    "    n_scans = func_img.shape[-1]\n",
    "    frame_times = np.arange(n_scans)*t_r\n",
    "    dm = make_first_level_design_matrix(frame_times,\n",
    "                                        event,drift_model=drift_model,\n",
    "                                        drift_order=drift_order,\n",
    "                                        add_regs=dm_pm\n",
    "                                        [['EA_pmod','csf_fixed',\n",
    "                                          'white_matter_fixed',\n",
    "                                          'framewise_displacement',\n",
    "                                          'trans_x','trans_x_derivative1',\n",
    "                                          'trans_y','trans_y_derivative1',\n",
    "                                          'trans_z','trans_z_derivative1',\n",
    "                                          'rot_x','rot_x_derivative1',\n",
    "                                          'rot_y','rot_y_derivative1',\n",
    "                                          'rot_z','rot_z_derivative1']],\n",
    "                                        add_reg_names=['EA_pmod','csf_fixed',\n",
    "                                          'white_matter_fixed',\n",
    "                                          'framewise_displacement',\n",
    "                                          'trans_x','trans_x_derivative1',\n",
    "                                          'trans_y','trans_y_derivative1',\n",
    "                                          'trans_z','trans_z_derivative1',\n",
    "                                          'rot_x','rot_x_derivative1',\n",
    "                                          'rot_y','rot_y_derivative1',\n",
    "                                          'rot_z','rot_z_derivative1'],\n",
    "                                        hrf_model=hrf_model,)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dm.to_csv('/projects/ttan/fMRI_tools/analysis/sub-CMH0012/sub-CMH0012_design_matrix_run-01_fixed.tsv', sep = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "global t_r\n",
    "global tr_drop\n",
    "global drift_model\n",
    "global drift_order\n",
    "global hrf_model\n",
    "global noise_model\n",
    "global period_cut\n",
    "global event_df\n",
    "global confound_df\n",
    "global frame_times\n",
    "\n",
    "#Define the time repettion from bid json file \n",
    "import os\n",
    "data_dir='/archive/data/SPINS/data/bids'\n",
    "json_file = os.path.join(data_dir,'sub-CMH0012', 'ses-01/func',\n",
    "                         'sub-CMH0012_ses-01_task-emp_run-1_bold.json')\n",
    "import json\n",
    "with open(json_file, 'r') as f:\n",
    "    t_r = json.load(f)['RepetitionTime']\n",
    "    \n",
    "#t_r=2\n",
    "frame_times = np.arange(n_scans)*t_r\n",
    "\n",
    "\n",
    "# design matrix input\n",
    "drift_model = 'polynomial'\n",
    "drift_order = 5\n",
    "hrf_model = 'spm'\n",
    "\n",
    "# first level model input\n",
    "noise_model = 'ar1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_localizer_contrasts(dm):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments: \n",
    "    \n",
    "    dm       the full deisgn matrix\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    contrasts  a dict list of contrasts\n",
    "    \n",
    "    \"\"\"\n",
    "    contrast_matrix = np.eye(dm.shape[1])\n",
    "    contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(dm.columns)])\n",
    "    \n",
    "    button_press_main = contrasts['circle_button_press'] + contrasts['EA_button_press']\n",
    "    contrasts['button_press_main'] = contrasts['circle_button_press'] + contrasts['EA_button_press']\n",
    "    return contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for 1st level GLM\n",
    "first_level_glm=FirstLevelModel(t_r=t_r, #TR 2\n",
    "                        noise_model=noise_model, #ar1\n",
    "                        standardize=False,\n",
    "                        hrf_model=hrf_model,     #spm\n",
    "                        drift_model=drift_model, #polynomial\n",
    "                        drift_order=drift_order, #5\n",
    "                        high_pass=.01,\n",
    "                        mask_img=False,\n",
    "                        minimize_memory=False)\n",
    "#run FirstLevelModel.fit \n",
    "first_level_glm= first_level_glm.fit(nifti_img,design_matrices=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "out_path='/projects/ttan/fMRI_tools/analysis/sub-CMH0012'\n",
    "\n",
    "try:\n",
    "    # Create target Directroy\n",
    "    os.mkdir(out_path)\n",
    "    print(\"Directory \", out_path, \" Created \")\n",
    "except FileExistsError:\n",
    "    print(\"Directory \", out_path, \" already exists\")\n",
    "\n",
    "def compute_t_maps(first_level_model):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:  \n",
    "    \n",
    "    first_level_model     the GLM model\n",
    "    \n",
    "    Outputs: \n",
    "    \n",
    "    nifti imgs            t-stat maps of the contrasts\n",
    "             \n",
    "    \n",
    "    \"\"\"\n",
    "    design_matrix = first_level_glm.design_matrices_[0]\n",
    "    # Call the contrasts specification within the function\n",
    "    contrasts = make_localizer_contrasts(design_matrix)\n",
    "    contrasts_id = ['EA_block','EA_pmod','circle_block','button_press_main']\n",
    "    for i, val in enumerate(contrasts_id):\n",
    "        t_map = first_level_glm.compute_contrast(contrasts[contrasts_id[i]],\n",
    "                                                 stat_type='t',\n",
    "                                                 output_type='stat') # Can be ‘z_score’, ‘stat’, ‘p_value’, ‘effect_size’, ‘effect_variance’ or ‘all’\n",
    "        index= \"1\"\n",
    "        subject_tmap_path = os.path.join(out_path,\"{}_run-{}_t_map.nii.gz\".format(contrasts_id[i],index))\n",
    "        t_map.to_filename (subject_tmap_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# residuals=first_level_glm.residuals[0]\n",
    "# betas=first_level_glm.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_GLM_outputs(first_level_model):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    first_level_model    the GLM model\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    nifti img            the residuals && predicted time series\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    residuals=first_level_glm.residuals[0]\n",
    "    subject_residuals_path = os.path.join(out_path,\"residual_run-01.nii.gz\")\n",
    "    predicted=first-level_glm.predicted[0]\n",
    "    subject_predicted_path = os.path.join(out_path,\"predicted_run-01.nii.gz\")\n",
    "    residuals.to_filename (subject_residuals_path)\n",
    "    predicted.to_filename (subject_predicted_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
