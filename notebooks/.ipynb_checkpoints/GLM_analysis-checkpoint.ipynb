{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-618b5c292ed7>:12: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n",
      "  from nistats.design_matrix import make_first_level_design_matrix, make_second_level_design_matrix\n",
      "/mnt/tigrlab/projects/ttan/fMRI_tools/.fMRI_env/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bids import BIDSLayout\n",
    "import nibabel as nib\n",
    "from nistats.design_matrix import make_first_level_design_matrix, make_second_level_design_matrix\n",
    "from nistats.design_matrix import check_design_matrix\n",
    "from nistats.reporting import plot_design_matrix, plot_contrast_matrix\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.model import TContrastResults\n",
    "from nilearn import surface\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_epi, plot_img, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_events(event_file):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        event_file Full path to events.tsv file\n",
    "    \n",
    "    Output:\n",
    "        event_df Newly formatted events dataframe\n",
    "    \"\"\"\n",
    "    #Read in tsv file\n",
    "    event_df = pd.read_csv(event_file,delimiter='\\t')\n",
    "    \n",
    "    #Filter out the desired columns from event_df \n",
    "    event= event_df[['trial_type','onset','duration']]\n",
    " \n",
    "    #Define EA and Circle video trial types\n",
    "    EA_videos = event[event_df['trial_type'] == 'EA_block']\n",
    "    circle_videos = event[event_df['trial_type'] == 'circle_block']\n",
    "    \n",
    "    #Define button press event type from dataframe\n",
    "    button_press = event_df[['onset','event_type','stim_file','duration']]\n",
    "    button_press = button_press[button_press['event_type'] == 'button_press']\n",
    "\n",
    "    #Filter button press during circle stimulus\n",
    "    circle_button_press = button_press[button_press['stim_file'].str.match(\"circles\")]\n",
    "    EA_button_press = button_press[button_press['stim_file'].str.match(\"NW|AR|TA\")]\n",
    "    \n",
    "    #Rename the button_press during circle block to circle button press\n",
    "    circle_button_press=circle_button_press.reset_index(drop=True)\n",
    "    circle_button_press.loc[:,'event_type'] = 'circle_button_press'\n",
    "    EA_button_press=EA_button_press.reset_index(drop=True)\n",
    "    EA_button_press.loc[:,'event_type'] = 'EA_button_press'\n",
    "    EA_button_press[\"event_type\"].replace({\"button_press\": \"EA_button_press\"}, inplace=True)   \n",
    "\n",
    "    #Merge EA and circle button press together\n",
    "    df_button_press = pd.concat([EA_button_press,circle_button_press])\n",
    "\n",
    "    #Drop stim_file column in the button press dataframe\n",
    "    df_button_press.drop(['stim_file'], axis=1,inplace=True)\n",
    "    \n",
    "    #Rename event_type column to trial_type in button press df\n",
    "    df_button_press.rename(columns={\"event_type\": \"trial_type\"}, inplace=True)\n",
    "    \n",
    "    #Merge all the event types together\n",
    "    event_df = pd.concat([EA_videos,circle_videos,df_button_press])\n",
    "    event_df=event_df.reset_index(drop=True)\n",
    "    #final_df.to_csv('/projects/ttan/fMRI_tools/sub-CMH0012_EA_onsets_run-01_fixed.tsv', sep = '\\t')\n",
    "    \n",
    "    return event_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_confounds(confound_path,fixed_confound_path, confound_vars):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        confound_path    Full path to confounds.tsv\n",
    "        confound_vars    List of confound variables to extract\n",
    "        tr_drop\n",
    "        dt               Compute temporal derivatives [default = True]\n",
    "        sq               Compute quadratic terms [default = False]\n",
    "    \n",
    "    Outputs:\n",
    "        confound_df\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in data using pandas and extract the relevant columns\n",
    "    confound_df = pd.read_csv(confound_path, delimiter='\\t')\n",
    "    confound_df = confound_df[confound_vars]\n",
    "    \n",
    "    #Load in the fixed csf and white matter data\n",
    "    fixed_confound_df = pd.read_csv(fixed_confound_path, delimiter='\\t')\n",
    "    confound_df[['csf','white_matter']] = fixed_confound_df[['csf_fixed','white_matter_fixed']].values\n",
    "    \n",
    "    # During the initial stages of a functional scan there is a strong signal decay artifact\n",
    "    # The first few TRs are very high intensity signals that don't reflect the rest of the scan\n",
    "    # so they are dropped\n",
    "    confound_df = confound_df.loc[tr_drop:].reset_index(drop=True)\n",
    "    \n",
    "    # Return confound matrix\n",
    "    return confound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parametric modulation for EA_video \n",
    "def get_dm_pmod(fmri_img,event_file,confound_df):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "        fmri_img        Full path to ciftify outputs\n",
    "        event_file      Full path to event tsv file\n",
    "        confound_df     output from extract_confounds\n",
    "    \n",
    "    Outputs:\n",
    "        dm_pm\n",
    "    \"\"\"\n",
    "    #Calculate frame times\n",
    "    func_img = nib.load(fmri_img)\n",
    "    n_scans = func_img.shape[-1]\n",
    "    frame_times = np.arange(n_scans)*t_r\n",
    "    \n",
    "    #Filter out EA_pmod from event file\n",
    "    #event_file = '/mnt/tigrlab/projects/ttan/fMRI_tools/data/preprocessed/sub-CMH0012/SPN01_CMH_0012_01_01_EMP_part1.tsv' \n",
    "    event = pd.read_csv(event_file,delimiter='\\t')\n",
    "    event= event[['trial_type','onset','duration','block_score']]\n",
    "    \n",
    "    EA_videos_pmod = event[event['trial_type']=='EA_block']\n",
    "    EA_videos_pmod=EA_videos_pmod.reset_index(drop=True)\n",
    "\n",
    "    # This approach allow separating the modulated regressor from the main effect regressor\n",
    "    EA_videos_pmod.rename(columns= {\"block_score\": \"modulation\"}, inplace=True)\n",
    "    #mean-cneter modulation to orthogonalize w.r.t main effect of condition\n",
    "    EA_videos_pmod['modulation']= EA_videos_pmod['modulation'] - EA_videos_pmod['modulation'].mean()\n",
    "\n",
    "    EA_videos_pmod[\"trial_type\"].replace({\"EA_block\": \"EA_pmod\"}, inplace=True)\n",
    "    # create design matrix with modulation\n",
    "    dm_pm = make_first_level_design_matrix(frame_times,EA_videos_pmod,\n",
    "                                           drift_model=drift_model,\n",
    "                                           drift_order=drift_order,\n",
    "                                           add_regs=confound_df,\n",
    "                                           add_reg_names=list(confound_df.columns),\n",
    "                                           hrf_model=hrf_model\n",
    "                                          )\n",
    "    \n",
    "    return dm_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove modulation column from event_df\n",
    "#Create a design matrix with pmod as the reressor\n",
    "def get_design_matrix(fmri_img,event_file,dm_pm):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    fmri_img        full path to functional data\n",
    "    event_file      full path to event type tsv file\n",
    "    dm_pm           design matrix for parametric modulation\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    dm              a full design matrix\n",
    "    \"\"\"\n",
    "    event=format_events(event_file)\n",
    "    func_img = nib.load(fmri_img)\n",
    "    n_scans = func_img.shape[-1]\n",
    "    frame_times = np.arange(n_scans)*t_r\n",
    "    dm = make_first_level_design_matrix(frame_times,\n",
    "                                        event,drift_model=drift_model,\n",
    "                                        drift_order=drift_order,\n",
    "                                        add_regs=dm_pm\n",
    "                                        [['EA_pmod','csf_fixed',\n",
    "                                          'white_matter_fixed',\n",
    "                                          'framewise_displacement',\n",
    "                                          'trans_x','trans_x_derivative1',\n",
    "                                          'trans_y','trans_y_derivative1',\n",
    "                                          'trans_z','trans_z_derivative1',\n",
    "                                          'rot_x','rot_x_derivative1',\n",
    "                                          'rot_y','rot_y_derivative1',\n",
    "                                          'rot_z','rot_z_derivative1']],\n",
    "                                        add_reg_names=['EA_pmod','csf_fixed',\n",
    "                                          'white_matter_fixed',\n",
    "                                          'framewise_displacement',\n",
    "                                          'trans_x','trans_x_derivative1',\n",
    "                                          'trans_y','trans_y_derivative1',\n",
    "                                          'trans_z','trans_z_derivative1',\n",
    "                                          'rot_x','rot_x_derivative1',\n",
    "                                          'rot_y','rot_y_derivative1',\n",
    "                                          'rot_z','rot_z_derivative1'],\n",
    "                                        hrf_model=hrf_model,)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dm.to_csv('/projects/ttan/fMRI_tools/analysis/sub-CMH0012/sub-CMH0012_design_matrix_run-01_fixed.tsv', sep = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global t_r\n",
    "global tr_drop\n",
    "global drift_model\n",
    "global drift_order\n",
    "global hrf_model\n",
    "global noise_model\n",
    "global period_cut\n",
    "global event_df\n",
    "global confound_df\n",
    "global frame_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_localizer_contrasts(dm):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments: \n",
    "    \n",
    "    dm       the full deisgn matrix\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    contrasts  a dict list of contrasts\n",
    "    \n",
    "    \"\"\"\n",
    "    contrast_matrix = np.eye(dm.shape[1])\n",
    "    contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(dm.columns)])\n",
    "    \n",
    "    button_press_main = contrasts['circle_button_press'] + contrasts['EA_button_press']\n",
    "    contrasts['button_press_main'] = contrasts['circle_button_press'] + contrasts['EA_button_press']\n",
    "    return contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all the constants to run FirstLevelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base_path='/projects/ttan/fMRI_tools'\n",
    "input_path='{}/data/preprocessed'.format(base_path)\n",
    "out_path='{}/analysis'.format(base_path)\n",
    "\n",
    "fmri_sub=os.path.join(input_path,'{subject}')\n",
    "fmri_img='{subject}_ses-01_task-{task}_run-{run}_desc-preproc_Atlas_s6.nii'\n",
    "cifti_img='{subject}_ses-01_task-{task}_run-{run}_desc-preproc_Atlas_s6.dtseries.nii'\n",
    "event_file='SPN01_CMH_{sub_id}_01_01_EMP_part{run}.tsv'\n",
    "confound_file='{subject}_ses-01_task-{task}_run-{run}_desc-confounds_regressors.tsv'\n",
    "fixed_confound_file='{subject}_ses-01_task-{task}_run-{run}_desc-confounds_regressors_fixed.tsv'\n",
    "\n",
    "#subjects\n",
    "with open('/projects/ttan/fMRI_tools/lists/subs.txt','r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "subjects = [i for i in lines[:-1]]\n",
    "subs_id = [i.replace('sub-CMH', '') for i in lines][:-1]\n",
    "#df=pd.DataFrame(subs_id)\n",
    "#df.to_csv('/projects/ttan/fMRI_tools/lists/subs_id.csv',index=False)\n",
    "\n",
    "task='emp'\n",
    "runs= ['1','2','3']\n",
    "\n",
    "#Define the time repettion from bid json file \n",
    "data_dir='/archive/data/SPINS/data/bids'\n",
    "json_file = os.path.join(data_dir,'sub-CMH0012', 'ses-01/func',\n",
    "                         'sub-CMH0012_ses-01_task-emp_run-1_bold.json')\n",
    "import json\n",
    "with open(json_file, 'r') as f:\n",
    "    t_r = json.load(f)['RepetitionTime']\n",
    "tr_drop=4    \n",
    "#t_r=2\n",
    "#frame_times = np.arange(n_scans)*t_r\n",
    "\n",
    "# design matrix input\n",
    "drift_model = 'polynomial'\n",
    "drift_order = 5\n",
    "hrf_model = 'spm'\n",
    "\n",
    "# first level model input\n",
    "noise_model = 'ar1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate design matrix output \n",
    "for subject in subjects:\n",
    "    sub_id=subject.replace('sub-CMH','')\n",
    "    out_dir = os.path.join(out_path, 'first_lvl',subject)\n",
    "    for run in runs:\n",
    "        \n",
    "        #Path to the event tsv files\n",
    "        event_file=\"SPN01_CMH_{sub_id}_01_01_EMP_part{run}.tsv\"\n",
    "        event_file=os.path.join(input_path,subject,event_file.format(sub_id=sub_id,run=run))\n",
    "        \n",
    "        #Path to fmriprep tsv confound files\n",
    "        confound_file='{subject}_ses-01_task-{task}_run-{run}_desc-confounds_regressors.tsv'\n",
    "        confounds=os.path.join(input_path,subject,confound_file.format(subject=subject,task=task,run=run))\n",
    "\n",
    "        #Path to fmriprep fixed tsv confound files\n",
    "        fixed_confound_file='{subject}_ses-01_task-{task}_run-{run}_desc-confounds_regressors_fixed.tsv'\n",
    "        fixed_confounds=os.path.join(input_path,subject,fixed_confound_file.format(subject=subject,task=task,run=run))\n",
    "        \n",
    "        #Path to fmriprep functional image\n",
    "        fmri_sub=os.path.join(input_path,'{subject}')\n",
    "        fmri_img=os.path.join(fmri_sub,'{subject}_ses-01_task-{task}_run-{run}_desc-preproc_Atlas_s6.nii')\n",
    "        fmri_file=fmri_img.format(subject=subject,task=task,run=run)\n",
    "        \n",
    "        #Define confound regressors\n",
    "        confound_vars = ['csf','white_matter','framewise_displacement',\n",
    "                         'trans_x','trans_y','trans_z',\n",
    "                         'trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                         'rot_x','rot_y','rot_z',\n",
    "                         'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1',\n",
    "                        ]\n",
    "        #Extract desired confound components\n",
    "        confound_df= extract_confounds(confounds,fixed_confounds,confound_vars)\n",
    "        \n",
    "        #Create a design matrix with parametric modulation\n",
    "        dm_pm = get_dm_pmod(fmri_file,event_file,confound_df)\n",
    "        \n",
    "        #Create a full design matrix \n",
    "        dm = get_design_matrix(fmri_file,event_file,dm_pm)\n",
    "        \n",
    "        #Generate the full design matrix output\n",
    "        combined_dm_path = os.path.join(out_dir, '{}_ses-01_task-{}_run-{}_dm.tsv'.format(subject,task,run))\n",
    "\n",
    "        try:\n",
    "            os.makedirs(out_dir)\n",
    "            print(\"Directory \", out_dir, \" Created \")\n",
    "        except FileExistsError:\n",
    "            print(\"Directory \", out_dir, \" already exists\")\n",
    "        print(subject)\n",
    "        dm.to_csv(combined_dm_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting the firstlevelmodel with multiple runs for multiple subjects\n",
    "for subject in subjects:\n",
    "    fmri_combined= [];\n",
    "    first_lvl_dms=  [];\n",
    "    subj_outdir = os.path.join(out_path, 'first_lvl',subject)\n",
    "    for run in runs:\n",
    "        fmri_sub=os.path.join(input_path,'{subject}')\n",
    "        fmri_img=os.path.join(fmri_sub,'{subject}_ses-01_task-{task}_run-{run}_desc-preproc_Atlas_s6.nii')\n",
    "        fmri_file=fmri_img.format(subject=subject,task=task,run=run)\n",
    "        fmri_combined.append(fmri_file)\n",
    "        combined_dm_path = os.path.join(subj_outdir, '{}_ses-01_task-{}_run-{}_dm.tsv'.format(subject,task,run))\n",
    "        dm=pd.read_csv(combined_dm_path,delimiter='\\t',index_col=[0])\n",
    "        first_lvl_dms.append(dm)     \n",
    "        \n",
    "    contrast_matrix = np.eye(dm.shape[1])\n",
    "    basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                         for i, column in enumerate(dm.columns)])\n",
    "    basic_contrasts['button_press_main'] = basic_contrasts['circle_button_press'] + basic_contrasts['EA_button_press']\n",
    "    contrasts_id = ['EA_block','EA_pmod','circle_block','button_press_main']\n",
    "    \n",
    "    first_level_glm=FirstLevelModel(t_r=t_r, #TR 2\n",
    "                                    noise_model=noise_model, #ar1\n",
    "                                    standardize=False,\n",
    "                                    hrf_model=hrf_model,     #spm\n",
    "                                    drift_model=drift_model, #polynomial\n",
    "                                    drift_order=drift_order, #5\n",
    "                                    minimize_memory=False,\n",
    "                                    #high_pass=.01,\n",
    "                                    mask_img=False)   \n",
    "    first_level_glm = first_level_glm.fit(fmri_combined,design_matrices=first_lvl_dms)\n",
    "\n",
    "    for i, val in enumerate(contrasts_id):\n",
    "        t_map = first_level_glm.compute_contrast(basic_contrasts[contrasts_id[i]],\n",
    "                                                 stat_type='t',\n",
    "                                                 output_type='stat')\n",
    "        subject_tmap_path = os.path.join(subj_outdir,\"{}_ses-01_task-{}_{}_t_map.nii.gz\".format(subject,task,contrasts_id[i]))\n",
    "        t_map.to_filename (subject_tmap_path)\n",
    "        \n",
    "          #generate the effect size/beta img output\n",
    "#         for contrast in basic_contrasts:\n",
    "#             eff_size=first_lvl_glm.compute_contrast(basic_contrasts[contrast],\n",
    "#                                                     stat_type='t',\n",
    "#                                                     output_type='effect_size')\n",
    "#             subject_outpath= os.path.join(subj_outdir,\"{}_ses-01_task-{}_run-{}-{}_effect_size.nii.gz\".format(subject,task,run,contrast))\n",
    "#             eff_size.to_filename(subject_outpath)\n",
    "        \n",
    "    \n",
    "#         #Generate residual output\n",
    "#         subject_residual_path= os.path.join(subj_outdir,\"{}_ses-01_task-{}_run-{}_residual.nii.gz\".format(subject,task,run))\n",
    "#         residuals=first_lvl_glm.residuals[0] \n",
    "#         residuals.to_filename(subject_residual_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
